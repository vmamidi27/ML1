{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8065aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1774b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e8c2de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PC1          PC2\n",
      "0 -4322.502965   912.075900\n",
      "1  4122.881755 -2440.379395\n",
      "2  1500.437024 -2003.323087\n",
      "3  1279.846965 -1330.413945\n",
      "4 -3739.093063   748.091636\n"
     ]
    }
   ],
   "source": [
    "# 1 A\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:/Users/Vinay Vivek/Desktop/ML/datasets (1) (1)/datasets/CC GENERAL.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df.drop(['CUST_ID'], axis=1, inplace=True)\n",
    "\n",
    "# Fill missing values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Apply PCA with 2 principal components\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df)\n",
    "\n",
    "# Convert to dataframe and display results\n",
    "df_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n",
    "print(df_pca.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed4c933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score with PCA: 0.5976848356156088\n"
     ]
    }
   ],
   "source": [
    "# 1 B\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Apply k-means with 2 clusters on the PCA result\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(df_pca)\n",
    "\n",
    "# Calculate the silhouette score\n",
    "score_pca = silhouette_score(df_pca, kmeans.labels_)\n",
    "print('Silhouette score with PCA:', score_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b9fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score with Scaling+PCA+K-Means: 0.46463936873119793\n"
     ]
    }
   ],
   "source": [
    "# 1 C\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Apply PCA with 2 principal components on the scaled data\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Apply k-means with 2 clusters on the PCA result\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(df_pca)\n",
    "\n",
    "# Calculate the silhouette score\n",
    "score_pca_scaled = silhouette_score(df_pca, kmeans.labels_)\n",
    "print('Silhouette score with Scaling+PCA+K-Means:', score_pca_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89e53813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1   0.85247   0.71826   0.57227       240       239  0.00806353  \\\n",
      "0  0.969987  0.122402 -0.080045  0.369063 -0.908356 -0.903716    1.041163   \n",
      "1  0.969987  0.618534 -0.349284  0.734104 -0.928523 -0.923846    1.085720   \n",
      "2 -1.030942 -1.978935  1.381764  0.754118 -1.473032 -1.467347    2.465243   \n",
      "3 -1.030942 -2.471167  1.397542  0.300800 -0.888189 -0.883586    0.988197   \n",
      "4 -1.030942 -1.408239  1.248651  1.204889 -0.989024 -1.024494    0.697643   \n",
      "\n",
      "   8.68E-05   0.00218  1.76E-05  ...    1.5466     1.562    2.6445    3.8686  \\\n",
      "0 -0.426396 -0.142549 -0.027630  ... -0.446084 -0.585415 -0.590358  0.192235   \n",
      "1 -0.443851 -0.214847 -0.088762  ... -0.446384 -0.585287 -0.629596 -0.356868   \n",
      "2 -0.275703  0.709812  1.256139  ... -0.322018 -0.532784 -0.591716 -0.522939   \n",
      "3  3.141324  1.151213  1.177541  ... -0.301265 -0.476112 -0.521963 -0.490638   \n",
      "4  3.179146  2.094897  1.876190  ... -0.337741 -0.508573 -0.545515 -0.453974   \n",
      "\n",
      "     4.2105    5.1221    4.4625    2.6202    3.0004   18.9405  \n",
      "0  0.015536 -0.067612 -0.176118 -0.527535 -0.583922  0.399682  \n",
      "1 -0.156614 -0.068084 -0.463869 -0.756890 -0.805290 -0.780974  \n",
      "2  0.007758 -0.450172 -0.471269 -0.634335 -0.589335 -0.801609  \n",
      "3 -0.405266 -0.250068 -0.042641 -0.420270 -0.673146 -0.741538  \n",
      "4 -0.393566 -0.394891 -0.303640 -0.725368 -0.780676 -0.826013  \n",
      "\n",
      "[5 rows x 753 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2 A\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:/Users/Vinay Vivek/Desktop/ML/datasets (1) (1)/datasets/pd_speech_features.csv\"\n",
    "df = pd.read_csv(file_path, skiprows=1)\n",
    "\n",
    "\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to dataframe and display results\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db98e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC1       PC2        PC3\n",
      "0 -10.612809  1.575370  -6.840102\n",
      "1 -13.487768 -1.261702  -6.830480\n",
      "2  -9.193958  8.854834  15.256822\n",
      "3  -6.800991  4.633417  15.614852\n",
      "4  -4.558235  1.786739  21.274654\n"
     ]
    }
   ],
   "source": [
    "# 2 B\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA with 3 principal components on the scaled data\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Convert to dataframe and display results\n",
    "df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "print(df_pca.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 C\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SVM on the training set\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score with SVM:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b9ca6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LDA1      LDA2\n",
      "0  8.084953  0.328454\n",
      "1  7.147163 -0.755473\n",
      "2  7.511378 -0.238078\n",
      "3  6.837676 -0.642885\n",
      "4  8.157814  0.540639\n"
     ]
    }
   ],
   "source": [
    "# 3 \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:/Users/Vinay Vivek/Desktop/ML/datasets (1) (1)/datasets/Iris.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(['Id', 'Species'], axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# Apply LDA with 2 components\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# Convert to dataframe and display results\n",
    "df_lda = pd.DataFrame(X_lda, columns=['LDA1', 'LDA2'])\n",
    "print(df_lda.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "\n",
    "The main difference between PCA and LDA is their objective. \n",
    "PCA is an unsupervised technique that aims to reduce the dimensionality of a dataset by maximizing the variance of the data. \n",
    "On the other hand, LDA is a supervised technique that aims to reduce the dimensionality of a dataset by maximizing \n",
    "the separability between classes. PCA finds a new set of orthogonal variables (principal components) that represent \n",
    "the most important features in the dataset, \n",
    "while LDA finds a new set of variables (linear discriminants) that maximize the ratio of between-class variance to \n",
    "within-class variance. PCA can be used for any type of data, while LDA is specifically designed for classification problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
